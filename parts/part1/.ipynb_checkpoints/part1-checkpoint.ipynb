{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e8875c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import numpy.typing as npt\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5f7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Generate sample data\n",
    "np.random.seed(42)  # For reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd03283b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "n_samples = 100\n",
    "true_slope = 2.5\n",
    "true_intercept = 5\n",
    "noise_level = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6ace6f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate x values\n",
    "X = np.random.uniform(0, 10, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3839abd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate y values with some noise to mimic \"real world\" phenomenon\n",
    "y = true_slope * X + true_intercept + np.random.normal(0, noise_level, n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bf09dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into training and testing sets (80% train, 20% test)\n",
    "split_idx = int(0.8 * n_samples)\n",
    "X_train, X_test = X[:split_idx], X[split_idx:]\n",
    "y_train, y_test = y[:split_idx], y[split_idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa6a516a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize parameters. In training, these random values will be adjusted through gradient descent\n",
    "weight = np.random.randn()  # coefficient/slope\n",
    "bias = np.random.randn()  # intercept"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f8b367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Define model functions\n",
    "def forward_pass(\n",
    "    x: npt.NDArray[np.float64], weight: float, bias: float\n",
    ") -> npt.NDArray[np.float64]:\n",
    "    return x * weight + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ec0146",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_calculation(\n",
    "    y_pred: npt.NDArray[np.float64], y_true: npt.NDArray[np.float64]\n",
    ") -> np.floating:\n",
    "    return np.mean((y_pred - y_true) ** 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "185b2f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parameter_update(\n",
    "    w: float,\n",
    "    b: float,\n",
    "    x: np.ndarray,\n",
    "    y: npt.NDArray[np.float64],\n",
    "    y_pred: npt.NDArray[np.float64],\n",
    "    learning_rate: float,\n",
    ") -> tuple[float, float]:\n",
    "    num_inputs = x.size\n",
    "    derivative_weight = -2 / num_inputs * np.sum(x * (y - y_pred))\n",
    "    derivative_bias = -2 / num_inputs * np.sum(y - y_pred)\n",
    "\n",
    "    weight = w - learning_rate * derivative_weight\n",
    "    bias = b - learning_rate * derivative_bias\n",
    "\n",
    "    return (weight, bias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af87309b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Training loop\n",
    "# Hyperparameters\n",
    "learning_rate = 0.01\n",
    "iterations = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10586221",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_history = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11aa6734",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(iterations):\n",
    "    y_pred = forward_pass(X_train, weight, bias)\n",
    "    loss = loss_calculation(y_pred, y_train)\n",
    "    loss_history.append(loss)\n",
    "\n",
    "    weight, bias = parameter_update(\n",
    "        weight, bias, X_train, y_train, y_pred, learning_rate\n",
    "    )\n",
    "\n",
    "    if (i + 1) % 100 == 0:\n",
    "        print(\n",
    "            f\"Iteration {i + 1}/{iterations}, Loss: {loss:.4f}, Weight: {weight:.4f}, Bias: {bias:.4f}\"\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eba48ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Final parameters: Weight = {weight:.4f}, Bias = {bias:.4f}\")\n",
    "print(f\"True parameters: Weight = {true_slope:.4f}, Bias = {true_intercept:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "925643ce",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "5. Visualization\n",
    "TODO: Plot original data points and final regression line\n",
    "TODO: Plot loss over iterations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa72bb0d",
   "metadata": {},
   "source": [
    "6. (Optional) Do this in a jupyter notebook\n",
    "TODO: convert this python script to a jupyter notebook to test inputs and outputs at each step"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
